# *****Linear Regression*****

So at first, we import NumPy, Pandas, Matplotlib, and Seaborn. ðŸ“¦

Then, from sklearn.datasets, we import the California housing dataset.

We also use the default train-test split function provided by sklearn.

Next, we import the Linear Regression model from sklearn.

And finally, we import the evaluation metrics: MSE (Mean Squared Error) and RÂ² score. ðŸ“‰

â¸»

Then we load the dataset.
Here, we use as_frame=True so that the dataset is returned as a Pandas DataFrame instead of NumPy arrays â€” this makes it easier to work with. âœ…

â¸»

	â€¢	X contains the data without the answers (features).
	â€¢	y contains the answers (target values).

We print both X and y to check them.

â¸»

Next, we split the data.
Weâ€™re taking out 20% from the total data for testing, and using 80% for training.
We use a random seed of 42 to ensure consistent results every time we run it.

â¸»

Now we train the model using X_train and y_train.

â¸»

Then we test the model by predicting target values using X_test.

â¸»

After that, we use the evaluation metrics we imported earlier:
	â€¢	MSE: Mean Squared Error
	â€¢	RMSE: Root Mean Squared Error
	â€¢	RÂ²: R-squared score â€” tells us how well the model fits the data

â¸»

Finally, we use Matplotlib to create a visual comparison of the actual vs predicted house values.

This helps us visually interpret how well our regression model is performing. ðŸ“Š
